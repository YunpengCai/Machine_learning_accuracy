{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from time import time\n",
    "sys.path.append(\"../tools/\")\n",
    "from email_preprocess import preprocess\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "### Chris label as 1, Sara label as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n"
     ]
    }
   ],
   "source": [
    "features_train, features_test, labels_train, labels_test = preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try kernel with linear first\n",
    "def svmaccuracy(features_train, features_test, labels_train, labels_test):\n",
    "\n",
    "\n",
    "\n",
    "    t0 = time()\n",
    "    clf=SVC(kernel='linear')\n",
    "    clf.fit(features_train, labels_train)\n",
    "    \n",
    "    print \"training time:\", round(time()-t0, 3), \"s\"        \n",
    "    \n",
    "    t0 = time()\n",
    "    pred=clf.predict(features_test)\n",
    "    print \"prediction time:\", round(time()-t0, 3), \"s\"\n",
    "    score=accuracy_score(labels_test,pred)\n",
    "    print score\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 246.546 s\n",
      "prediction time: 25.519 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9840728100113766"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmaccuracy(features_train, features_test, labels_train, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 0.154 s\n",
      "prediction time: 1.526 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8845278725824801"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downsize train dataset to save time\n",
    "features_train = features_train[:len(features_train)/100]\n",
    "labels_train = labels_train[:len(labels_train)/100]\n",
    "svmaccuracy(features_train, features_test, labels_train, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use kernel as rbf instead of linear\n",
    "def svmaccuracy_rbf(features_train, features_test, labels_train, labels_test, penalty=1):\n",
    "\n",
    "\n",
    "\n",
    "    t0 = time()\n",
    "    clf=SVC(kernel='rbf',C=penalty)\n",
    "    clf.fit(features_train, labels_train)\n",
    "    \n",
    "    print \"training time:\", round(time()-t0, 3), \"s\"        \n",
    "    \n",
    "    t0 = time()\n",
    "    pred=clf.predict(features_test)\n",
    "    print \"prediction time:\", round(time()-t0, 3), \"s\"\n",
    "    score=accuracy_score(labels_test,pred)\n",
    "    print score\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 0.168 s\n",
      "prediction time: 1.696 s\n",
      "0.6160409556313993\n"
     ]
    }
   ],
   "source": [
    "svmaccuracy_rbf(features_train, features_test, labels_train, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 0.168 s\n",
      "prediction time: 1.695 s\n",
      "0.6160409556313993\n",
      "training time: 0.164 s\n",
      "prediction time: 1.685 s\n",
      "0.6160409556313993\n",
      "training time: 0.156 s\n",
      "prediction time: 1.684 s\n",
      "0.8213879408418657\n",
      "training time: 0.152 s\n",
      "prediction time: 1.345 s\n",
      "0.8924914675767918\n"
     ]
    }
   ],
   "source": [
    "#Optimize parameter C in SVC\n",
    "for penalty in [10,100,1000,10000]:\n",
    "    svmaccuracy_rbf(features_train, features_test, labels_train, labels_test, penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n",
      "training time: 184.449 s\n",
      "prediction time: 19.525 s\n",
      "0.9908987485779295\n"
     ]
    }
   ],
   "source": [
    "# Run the SVC with full train data and optimized C\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "prediction=svmaccuracy_rbf(features_train, features_test, labels_train, labels_test, penalty=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check some specific prediction\n",
    "prediction[10],prediction[26],prediction[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "877"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many prediction are Chris(label as 1)\n",
    "sum(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py2]",
   "language": "python",
   "name": "conda-env-py2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
